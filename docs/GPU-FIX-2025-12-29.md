# GPU Transcoding Fix - 2025-12-29

**Issue:** GPU transcoding wasn't working after fresh cluster rebuild
**Root Cause:** Missing sysctl configuration
**Status:** ✅ FIXED

## Problem

After rebuilding the 3-node Talos cluster from scratch, GPU hardware transcoding for Plex was not working. Symptoms:
- NVIDIA Device Plugin crashed with BPF errors
- Any container using `runtimeClassName: nvidia` failed to start
- Error message:
  ```
  nvidia-container-cli: mount error: failed to add device rules:
  unable to create new device filters program: load program: invalid argument:
  last insn is not an exit or jmp
  ```

## Root Cause

The nvidia-container-runtime uses BPF (Berkeley Packet Filter) programs for device filtering in containers. On Talos Linux with cgroupsv2, these BPF programs require the kernel sysctl `net.core.bpf_jit_harden` to be set to `1`.

**This sysctl was missing** from the fresh node .20 installation, even though:
- NVIDIA kernel modules were loaded ✓
- NVIDIA factory image was installed ✓
- ext-nvidia-persistenced service was running ✓
- NVIDIA RuntimeClass was deployed ✓

## The Fix

Apply the sysctl via machine config patch:

```bash
cat > /tmp/gpu-sysctl-patch.yaml <<'EOF'
machine:
  sysctls:
    net.core.bpf_jit_harden: 1
EOF

talosctl --nodes 192.168.2.20 patch machineconfig --patch @/tmp/gpu-sysctl-patch.yaml
```

**No reboot required** - the sysctl is applied immediately.

## Verification

After applying the fix:

1. **Device Plugin Started Successfully:**
   ```bash
   kubectl get pods -n kube-system -l name=nvidia-device-plugin-ds
   # nvidia-device-plugin-daemonset-2cxs9   1/1     Running
   ```

2. **GPU Resource Advertised:**
   ```bash
   kubectl describe node talos-hfv-ykp | grep nvidia.com/gpu
   # nvidia.com/gpu     1             1
   ```

3. **Plex Started with GPU Access:**
   ```bash
   kubectl exec -n media deployment/plex -- nvidia-smi
   # Shows GTX 1050 Ti
   ```

4. **Plex Running on Node .20:**
   ```bash
   kubectl get pods -n media -o wide
   # plex-d88fc79d5-5kjdw   1/1     Running   talos-hfv-ykp
   ```

## Why This Happened

The sysctl configuration was present in `talos/patches/gpu-patch.yaml`:
```yaml
machine:
  kernel:
    modules:
      - name: nvidia
      - name: nvidia_uvm
      - name: nvidia_drm
      - name: nvidia_modeset
  sysctls:
    net.core.bpf_jit_harden: 1  # <-- This line
```

However, during the fresh cluster rebuild, we only applied the kernel modules patch and forgot the sysctl. The kernel modules alone are sufficient to get the node into "running" stage, but the sysctl is required for the nvidia-container-runtime to actually work.

## Previous Working State

GPU transcoding was working before (commit 7264fb2 from Dec 11, 2025) because the full gpu-patch.yaml with both kernel modules AND the sysctl was properly applied to the node.

## Complete GPU Setup Requirements

For GPU transcoding to work on node .20, ALL of these are required:

1. ✅ **NVIDIA Factory Image**
   - `factory.talos.dev/installer/86a5d7c9beb23b4aea2777e44ca06c8c2ceea8a874ccd2b9a6743c4f734329e0:v1.11.5`

2. ✅ **Kernel Modules** (or node stays in "booting")
   ```yaml
   machine:
     kernel:
       modules:
         - name: nvidia
         - name: nvidia_uvm
         - name: nvidia_drm
         - name: nvidia_modeset
   ```

3. ✅ **BPF JIT Harden Sysctl** (or nvidia runtime fails)
   ```yaml
   machine:
     sysctls:
       net.core.bpf_jit_harden: 1
   ```

4. ✅ **NVIDIA RuntimeClass**
   ```yaml
   apiVersion: node.k8s.io/v1
   kind: RuntimeClass
   metadata:
     name: nvidia
   handler: nvidia
   ```

5. ✅ **NVIDIA Device Plugin**
   - Must use `runtimeClassName: nvidia`
   - Advertises `nvidia.com/gpu` resource to Kubernetes

6. ✅ **Plex Deployment**
   - Uses `runtimeClassName: nvidia`
   - Requests `nvidia.com/gpu: 1`
   - Sets `NVIDIA_VISIBLE_DEVICES=all`
   - Scheduled on node with GPU (talos-hfv-ykp / .20)

## Current Status

**All components working:**
- Node .20: Running with GPU support
- GPU: NVIDIA GeForce GTX 1050 Ti
- Device Plugin: Running and advertising GPU
- Plex: Running with GPU access on .20
- Access: http://192.168.2.20:32400

## Documentation Updated

Files updated to include sysctl requirement:
- `docs/talos-gpu-setup.md` - Added CRITICAL warning about sysctl
- `docs/3-node-cluster-DR.md` - Updated Step 5 to include sysctl
- `docs/CLUSTER-STATUS.md` - Marked GPU as working
- `docs/README.md` - Added lesson learned about sysctl
- `docs/GPU-FIX-2025-12-29.md` - This document

## Key Takeaway

**The sysctl `net.core.bpf_jit_harden: 1` is just as critical as the kernel modules for GPU support.** Without it, the NVIDIA runtime completely fails even though the GPU is detected and modules are loaded. Always apply BOTH together from `talos/patches/gpu-patch.yaml`.
